{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_path = \"./data/cora/cora.content\"\n",
    "idx_features_labels = np.genfromtxt(content_path, dtype=np.dtype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(labels):\n",
    "    # 获取类别数\n",
    "    classes = set(labels)\n",
    "    # 生成一个对角矩阵，并生成标签和编码向量对应的字典\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = encode_onehot(idx_features_labels[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立图结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "idx_map = {j: i for i, j in enumerate(idx)}\n",
    "edges_unordered = np.genfromtxt(\"./data/cora/cora.cites\", dtype=np.int32)\n",
    "edges = np.array(list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32).reshape(edges_unordered.shape)\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
    "\n",
    "# 建立对称矩阵\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 2708)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征正则化和邻接矩阵正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "def normalize_features(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = normalize_features(features)\n",
    "adj = normalize_adj(adj + sp.eye(adj.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 2705, 2706, 2707]),\n",
       " array([3, 4, 0, ..., 2, 1, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = range(140)\n",
    "idx_val = range(200, 500)\n",
    "idx_test = range(500, 1500)\n",
    "\n",
    "adj = torch.FloatTensor(np.array(adj.todense()))\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(np.where(labels)[1])\n",
    "\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_val = torch.LongTensor(idx_val)\n",
    "idx_test = torch.LongTensor(idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT 模型定义\n",
    "\n",
    "1. 自定义注意力层；\n",
    "2. 结合注意力层定义图注意力神经网络模型；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义注意力层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    GAT layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "        \n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "    \n",
    "    def forward(self, input, adj):\n",
    "        h = torcn.mm(input, self.W)\n",
    "        N = h.size()[0]\n",
    "        a_input = torch.cat([h.repeat(1, N).])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0300, -0.0253, -0.0741,  ..., -0.0199, -0.0513, -0.0686],\n",
       "        [ 0.0845,  0.0470,  0.0734,  ...,  0.0197, -0.0161, -0.0497],\n",
       "        [-0.0503,  0.0409, -0.0848,  ..., -0.0310,  0.0731, -0.0131],\n",
       "        ...,\n",
       "        [ 0.0464, -0.0514,  0.0559,  ..., -0.0366, -0.0549, -0.0839],\n",
       "        [-0.0044, -0.0607, -0.0681,  ...,  0.0745,  0.0571, -0.0115],\n",
       "        [-0.0340,  0.0791,  0.0686,  ..., -0.0747,  0.0764,  0.0582]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.zeros(size=(features.size()[1], 128))\n",
    "nn.init.xavier_uniform_(W, gain=1.414)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 2708, 256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.mm(features, W)\n",
    "N = h.size()[0]\n",
    "\n",
    "a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * 128)\n",
    "a_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeakyReLU(negative_slope=0.2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leakyrelu = nn.LeakyReLU(0.2)\n",
    "leakyrelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2024e-01],\n",
       "        [-1.1419e-01],\n",
       "        [-1.7044e-01],\n",
       "        [ 1.7360e-01],\n",
       "        [ 1.7264e-02],\n",
       "        [ 7.2557e-02],\n",
       "        [ 4.5110e-02],\n",
       "        [-4.2041e-02],\n",
       "        [ 1.5762e-01],\n",
       "        [ 1.7810e-01],\n",
       "        [-2.0461e-01],\n",
       "        [ 1.1418e-01],\n",
       "        [ 4.2414e-02],\n",
       "        [ 1.4858e-01],\n",
       "        [-2.9029e-02],\n",
       "        [ 1.9405e-01],\n",
       "        [ 2.0378e-01],\n",
       "        [-1.9727e-01],\n",
       "        [ 1.9980e-01],\n",
       "        [ 1.8286e-01],\n",
       "        [ 6.9735e-02],\n",
       "        [ 4.1901e-02],\n",
       "        [-4.4165e-02],\n",
       "        [-9.8491e-02],\n",
       "        [-3.3567e-02],\n",
       "        [-2.1180e-01],\n",
       "        [-8.7822e-02],\n",
       "        [ 9.9121e-02],\n",
       "        [ 4.1836e-02],\n",
       "        [-1.0435e-01],\n",
       "        [-1.9050e-02],\n",
       "        [-1.3781e-01],\n",
       "        [-1.8584e-01],\n",
       "        [ 6.2340e-02],\n",
       "        [ 8.6222e-02],\n",
       "        [-1.9500e-01],\n",
       "        [-6.2649e-02],\n",
       "        [-2.0984e-01],\n",
       "        [-1.9376e-01],\n",
       "        [-8.9739e-02],\n",
       "        [ 2.1301e-01],\n",
       "        [ 1.2192e-01],\n",
       "        [-1.4777e-01],\n",
       "        [ 1.3574e-01],\n",
       "        [-1.2983e-01],\n",
       "        [ 3.5540e-02],\n",
       "        [-8.3298e-02],\n",
       "        [-1.2345e-01],\n",
       "        [ 4.2178e-02],\n",
       "        [-1.3819e-01],\n",
       "        [ 8.4871e-02],\n",
       "        [-1.7386e-01],\n",
       "        [ 7.4419e-02],\n",
       "        [ 1.9654e-02],\n",
       "        [-1.6031e-01],\n",
       "        [-1.7681e-01],\n",
       "        [ 7.8833e-02],\n",
       "        [ 4.8530e-02],\n",
       "        [ 2.1030e-01],\n",
       "        [-1.6583e-01],\n",
       "        [-1.1160e-01],\n",
       "        [ 2.5443e-02],\n",
       "        [-8.5361e-02],\n",
       "        [ 1.6744e-01],\n",
       "        [ 6.7578e-02],\n",
       "        [ 1.2692e-01],\n",
       "        [ 1.8892e-01],\n",
       "        [ 5.2476e-02],\n",
       "        [-1.9836e-01],\n",
       "        [ 1.3358e-01],\n",
       "        [ 1.1494e-01],\n",
       "        [ 1.7338e-01],\n",
       "        [ 1.3041e-01],\n",
       "        [ 7.8151e-02],\n",
       "        [-1.0700e-01],\n",
       "        [-7.3557e-02],\n",
       "        [ 1.6520e-01],\n",
       "        [ 1.4307e-01],\n",
       "        [ 8.8708e-02],\n",
       "        [-8.9237e-03],\n",
       "        [-1.1478e-01],\n",
       "        [-1.1179e-01],\n",
       "        [ 1.2323e-01],\n",
       "        [ 9.2163e-02],\n",
       "        [ 1.7356e-01],\n",
       "        [-1.6916e-01],\n",
       "        [-1.1639e-02],\n",
       "        [ 1.8885e-02],\n",
       "        [-1.8617e-01],\n",
       "        [-1.5977e-01],\n",
       "        [ 2.0082e-01],\n",
       "        [ 6.8929e-02],\n",
       "        [-1.7025e-01],\n",
       "        [ 2.0899e-01],\n",
       "        [-2.1599e-01],\n",
       "        [-1.5600e-01],\n",
       "        [ 4.3729e-02],\n",
       "        [ 4.2688e-02],\n",
       "        [-1.3272e-01],\n",
       "        [-8.6112e-02],\n",
       "        [ 1.1274e-01],\n",
       "        [-1.4970e-02],\n",
       "        [-5.5589e-02],\n",
       "        [ 1.3823e-01],\n",
       "        [ 3.9165e-02],\n",
       "        [-8.3425e-02],\n",
       "        [ 1.9814e-01],\n",
       "        [-1.7582e-01],\n",
       "        [ 1.0978e-01],\n",
       "        [ 1.6863e-01],\n",
       "        [ 1.0854e-01],\n",
       "        [-1.5402e-01],\n",
       "        [ 1.3681e-01],\n",
       "        [-1.8751e-01],\n",
       "        [-1.8814e-04],\n",
       "        [ 1.1780e-01],\n",
       "        [-5.6598e-03],\n",
       "        [-6.1769e-03],\n",
       "        [-4.2836e-02],\n",
       "        [-6.4806e-02],\n",
       "        [-1.2021e-01],\n",
       "        [ 1.3005e-01],\n",
       "        [ 1.8784e-01],\n",
       "        [ 1.1829e-01],\n",
       "        [ 1.1340e-01],\n",
       "        [ 1.7294e-01],\n",
       "        [ 4.6576e-02],\n",
       "        [-8.7297e-02],\n",
       "        [-3.6051e-02],\n",
       "        [ 7.4560e-02],\n",
       "        [-5.4837e-03],\n",
       "        [-2.4845e-02],\n",
       "        [-7.3056e-02],\n",
       "        [-1.3224e-01],\n",
       "        [ 8.0401e-02],\n",
       "        [-8.8938e-02],\n",
       "        [-4.2787e-02],\n",
       "        [ 1.5964e-01],\n",
       "        [-1.1594e-01],\n",
       "        [-1.4626e-01],\n",
       "        [ 1.9070e-01],\n",
       "        [-8.5033e-02],\n",
       "        [-1.6912e-01],\n",
       "        [-1.4042e-01],\n",
       "        [ 1.8963e-01],\n",
       "        [-7.0765e-02],\n",
       "        [ 1.3615e-01],\n",
       "        [-7.7005e-02],\n",
       "        [-1.1229e-01],\n",
       "        [-1.4738e-01],\n",
       "        [ 1.9588e-01],\n",
       "        [ 1.5946e-01],\n",
       "        [-3.9941e-02],\n",
       "        [ 1.4639e-01],\n",
       "        [-4.5958e-02],\n",
       "        [ 2.0541e-01],\n",
       "        [-1.9098e-01],\n",
       "        [ 1.0735e-03],\n",
       "        [-1.3864e-01],\n",
       "        [-1.8271e-01],\n",
       "        [ 6.0295e-03],\n",
       "        [-1.5597e-01],\n",
       "        [ 1.6776e-01],\n",
       "        [ 5.9235e-02],\n",
       "        [ 4.5254e-02],\n",
       "        [ 1.8374e-01],\n",
       "        [-1.3290e-01],\n",
       "        [ 1.5693e-01],\n",
       "        [-1.8496e-01],\n",
       "        [ 1.3688e-01],\n",
       "        [ 8.6718e-02],\n",
       "        [ 2.6221e-02],\n",
       "        [-1.6776e-01],\n",
       "        [ 2.0858e-01],\n",
       "        [-4.3021e-02],\n",
       "        [ 1.4053e-01],\n",
       "        [ 1.1625e-01],\n",
       "        [ 4.3610e-02],\n",
       "        [-4.9486e-02],\n",
       "        [-1.5433e-03],\n",
       "        [ 9.5257e-02],\n",
       "        [-1.7742e-01],\n",
       "        [-1.6764e-01],\n",
       "        [-7.5800e-02],\n",
       "        [ 1.2107e-03],\n",
       "        [ 2.0044e-01],\n",
       "        [ 6.6528e-02],\n",
       "        [ 7.3395e-02],\n",
       "        [-6.7994e-02],\n",
       "        [-4.3563e-02],\n",
       "        [-2.2055e-02],\n",
       "        [ 1.3107e-01],\n",
       "        [-1.7031e-01],\n",
       "        [ 1.8714e-01],\n",
       "        [-1.1278e-01],\n",
       "        [ 2.8442e-03],\n",
       "        [ 8.8205e-02],\n",
       "        [-2.0076e-01],\n",
       "        [ 2.3385e-02],\n",
       "        [ 1.3653e-01],\n",
       "        [-3.1155e-02],\n",
       "        [ 1.1016e-01],\n",
       "        [ 8.5255e-02],\n",
       "        [ 9.8772e-02],\n",
       "        [ 2.1374e-01],\n",
       "        [-5.8468e-02],\n",
       "        [-1.9506e-01],\n",
       "        [ 1.5907e-01],\n",
       "        [-1.4662e-01],\n",
       "        [ 1.5339e-01],\n",
       "        [ 7.2100e-02],\n",
       "        [ 2.1380e-01],\n",
       "        [-3.3900e-02],\n",
       "        [-9.3209e-02],\n",
       "        [ 8.1604e-02],\n",
       "        [ 1.5441e-01],\n",
       "        [-1.0099e-01],\n",
       "        [-1.0589e-01],\n",
       "        [-1.1965e-01],\n",
       "        [ 8.6422e-02],\n",
       "        [-5.8416e-02],\n",
       "        [ 1.5338e-01],\n",
       "        [-1.8479e-01],\n",
       "        [-1.4225e-01],\n",
       "        [ 9.2478e-02],\n",
       "        [ 9.7301e-02],\n",
       "        [ 2.0714e-01],\n",
       "        [ 2.6945e-02],\n",
       "        [ 1.1543e-01],\n",
       "        [-2.7656e-02],\n",
       "        [-1.9719e-01],\n",
       "        [ 1.7304e-01],\n",
       "        [-9.5935e-02],\n",
       "        [-8.6260e-02],\n",
       "        [-1.6084e-01],\n",
       "        [-1.3538e-01],\n",
       "        [-2.8229e-02],\n",
       "        [ 1.1201e-01],\n",
       "        [ 1.6957e-01],\n",
       "        [ 1.8045e-01],\n",
       "        [ 6.6321e-02],\n",
       "        [ 9.7002e-02],\n",
       "        [-5.6114e-02],\n",
       "        [-1.8934e-01],\n",
       "        [ 4.0804e-02],\n",
       "        [-1.4342e-01],\n",
       "        [ 1.9631e-01],\n",
       "        [-2.7018e-02],\n",
       "        [-8.3538e-02],\n",
       "        [-1.3871e-01],\n",
       "        [-9.6595e-02],\n",
       "        [-2.1391e-01],\n",
       "        [ 1.9898e-02],\n",
       "        [-1.4990e-01],\n",
       "        [ 1.6417e-01],\n",
       "        [-1.9472e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(size=(2*128, 1))\n",
    "nn.init.xavier_uniform_(a, gain=1.414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 2708])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = leakyrelu(torch.matmul(a_input, a)).squeeze(2)\n",
    "e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4185e-02, -3.4654e-03,  1.1915e-05,  ..., -9.2427e-03,\n",
       "         -1.7768e-03, -1.4830e-03],\n",
       "        [ 4.1635e-02,  1.2280e-04,  1.7462e-02,  ..., -5.7527e-03,\n",
       "          8.5660e-03,  1.0035e-02],\n",
       "        [ 8.9432e-03, -6.5138e-03, -3.0460e-03,  ..., -1.2291e-02,\n",
       "         -4.8252e-03, -4.5314e-03],\n",
       "        ...,\n",
       "        [-8.3743e-04, -9.1399e-03, -5.6721e-03,  ..., -1.4917e-02,\n",
       "         -7.4513e-03, -7.1575e-03],\n",
       "        [ 5.1216e-02,  9.7038e-03,  2.7043e-02,  ..., -3.8365e-03,\n",
       "          1.8147e-02,  1.9616e-02],\n",
       "        [ 2.2734e-02, -3.7557e-03, -2.8790e-04,  ..., -9.5330e-03,\n",
       "         -2.0671e-03, -1.7733e-03]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1703, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5012, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.2006,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.1991, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1995, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2470]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_vec = -9e15 * torch.ones_like(e)\n",
    "attention = torch.where(adj > 0, e, zero_vec)\n",
    "attention = F.softmax(attention, dim=1)\n",
    "attention = F.dropout(attention, 0.6, training=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_path = \"./data/cora/cora.content\"\n",
    "idx_features_labels = np.genfromtxt(content_path, dtype=np.dtype(str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
